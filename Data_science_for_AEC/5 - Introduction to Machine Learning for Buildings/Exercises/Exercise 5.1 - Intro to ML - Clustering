{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercise 5.1 - Intro to ML - Clustering","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dASKmO_NAPhl","colab_type":"text"},"source":["# Data Science for Construction, Architecture and Engineering\n","### Section 5 - Introduction to Machine Learning\n","## Exercise Set 5.1 - Introduction to ML - Clustering\n","\n","This exercise is related to the first half of Section 5 videos. Using the same data (Project Building Data Genome) and packages (sklearn, matplotlib) as in the videos. The following tasks are about supervised and unsupervised learning algorithms. \n","\n","\n","There is an introduction video available to explain the process of doing the next exercises.\n","\n","The developer of this exercise is [Mahmoud Abdelrahman](https://www.linkedin.com/in/mahmoudouf/), a Ph.D. student at NUS.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1Ki5GuClMOyp","colab_type":"text"},"source":["#### Setup the environment\n","\n","Let's set up the environment:"]},{"cell_type":"code","metadata":{"id":"pWpaAeCbABtP","colab_type":"code","colab":{}},"source":["# Import packages\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib\n","from matplotlib import cm\n","\n","import sklearn\n","from sklearn import metrics\n","\n","from scipy.cluster.vq import kmeans, vq, whiten\n","from scipy.spatial.distance import cdist\n","import numpy as np\n","from datetime import datetime\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"92fJuAiuuhdo","colab_type":"code","colab":{}},"source":["# Mount the drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","# Change directory location (hint: chdir)\n","os.chdir(\"/content/gdrive/My Drive/EDX Data Science for Construction, Architecture and Engineering/3 - Construction - Pandas Fundamentals/meter_data/\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3WB0N8fShrIW","colab_type":"text"},"source":["## Exercise 05.1.1 - Plot the average day-of-the-week consumption\n","\n","In this exercise, we need to plot the average day-of-the-week energy consumption from `UnivDorm_Ashleigh.csv` file. \n","\n","*   The X axis should be the day of the week. \n","*   the Y axis is the average daily consumption over the year. \n","\n","An example of the output should look like this: \n","\n","<center>\n","<img width=\"486\" alt=\"visualization\" src=\"https://user-images.githubusercontent.com/6969514/85218845-c81af200-b3d0-11ea-96fd-6bf970bcf811.png\">\n","</center>\n","\n","\n","**Hints**\n","1. Use the [DatetimeIndex](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html) property [`dayofweek`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.dayofweek.html) to get the day of the week from the timestamp. \n","2. Group the dataframe by the `dayofweek` column that you create.\n","\n","<!-- ### **Q1: What is the day of the week that has the highest average energy consumption throughout the year in `UnivDorm_Ashleigh`?**  -->\n","\n","Find the day of the week where `UnivDorm_Ashleigh` has the highest **average** energy consumption\n"]},{"cell_type":"code","metadata":{"id":"cYEU25ChJi5X","colab_type":"code","colab":{}},"source":["# Find the day of the week with the maximum average energy consumption\n","# YOUR CODE HERE\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8P_lyBXBJHO","colab_type":"text"},"source":["## Exercise 05.1.2 - Clustering\n","\n","<!-- We need to cluster the energy consumption from the file `UnivDorm_Ashleigh.csv` into **weekly load profile** using **two clusters**. The weekly load profile should cosist of 7 values representing the `dayofweek`.  -->\n","\n","<!-- ### **Q2: According to your results, How many vacation weeks were taken during this academic year?** -->\n","\n","Let's say we want to find two types of weekly consumption behaviour from the `UnivDorm_Ashleigh.csv` building. The first thing to do would be to create weekly load profiles.\n","\n","Each weekly profile consists of 7 values, one for each day of the week, of energy consumption. Thus, every week in the year worth of data from the building, is treated as **one** datapoint with 7 features.\n","\n","Since we already have a specific number of clusters in mind, we can use `k-means` to find which week correspond to each cluster.\n","\n","Remember that we have chosen the number of clusters arbitrarily, and given the datapoints (weekly profiles), `k-means` will find the ones that are close to each other assuming there are only 2 groups (see a more detailed explanation [here](https://mahmoudouf.wordpress.com/2019/05/12/k-means-clustering-simply/))\n","\n","Firstly, identify a cluster of weekly profiles with the lowest values of energy consumption. From there, find the **number of weeks** in the cluster.\n","\n","**Hint**: Plotting the weeks of each cluster, color coded, is a good way to see which cluster is made of the low-consuming weeks. \n","\n","**Hint**: For a more fair comparison, is good to start first by normalizing the consumption values. One way to do this is by applying **min-max normalization**. The formula is as follows:\n","\n","$x_{new} = \\frac{x_{original} - x_{min}}{x_{max} - x_{min}}$\n"]},{"cell_type":"code","metadata":{"id":"v1_QrvJUMDIY","colab_type":"code","colab":{}},"source":["# Reload the data file and create a normalized dataframe\n","# YOUR CODE HERE \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KQ2WtqgKQNI","colab_type":"code","colab":{}},"source":["# Create weekly profiles and day of week to the normalized dataframe. \n","# Create a pivoted DataFrame \n","# YOUR CODE HERE "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2E1WAbzjKQ-a","colab_type":"code","colab":{}},"source":["# Create two clusters out of the normlized dataframe using k-means\n","# YOUR CODE HERE "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXIlbhMIPZLj","colab_type":"code","colab":{}},"source":["# Assign the cluster number into a new column called \"ClusterNo\"\n","# YOUR CODE HERE "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_TzTYUCOyo0","colab_type":"code","colab":{}},"source":["# Plot the clusters with different colors and find the number of weeks with low energy consumption??\n","# YOUR CODE HERE "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tFG5KU9jWiZz","colab_type":"text"},"source":["## Exercise 05.1.3 - Creating a new line-based visualization - Advanced (optional)\n","\n","Now, for each cluster, calculate the **mean and standard deviation** of the consumption values, and plot the **mean** and the **standard deviation** in a duplicate visualization to the following graphic, except with two clusters instead of four.\n","\n","<center><img src=\"https://user-images.githubusercontent.com/6969514/81120853-1890da00-8f60-11ea-9861-4817e4c4587f.png\" width=\"60%\" style=\"align:center\"></center>\n","\n","You will be required to use some code that has not been shown in the videos.\n","\n","**Hint:** You can `groupby` by cluster number and then get the mean `.mean()` and the standard deviation `.std()` directly.\n","\n","**Hint:** Use matplotlib to [`fill_between`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.fill_between.html) the upper and the lower limits of the std"]},{"cell_type":"code","metadata":{"id":"hAcuGShWQwJq","colab_type":"code","colab":{}},"source":["# For each cluster calculate the mean and standard deviation to then use `fill_between` in matplotlib\n","# YOUR CODE HERE\n","\n","\n"],"execution_count":null,"outputs":[]}]}