{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMJwwDFRv82t"
   },
   "source": [
    "# Regressor de preços de casas\n",
    "Nesse exercício, aplicaremos modelos de regressão na predição de preços de casas na Califórnia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swRxhNZ4wVLI"
   },
   "source": [
    "Primeiramente, execute a célula abaixo para ler os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "vB_CPWkbqUm7",
    "outputId": "7758689a-62c6-4e51-9a45-1b1fd6df50ab"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('california_housing_train.csv')\n",
    "df_test = pd.read_csv('california_housing_test.csv')\n",
    "\n",
    "X = df.drop(['median_house_value'],1)\n",
    "y = df['median_house_value']\n",
    "X_test = df_test.drop(['median_house_value'],1)\n",
    "y_test = df_test['median_house_value']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZUOuNrGw0yH"
   },
   "source": [
    "# 1. Separação do conjunto de validação\n",
    "\n",
    "Os dados já vieram separados em conjuntos de treino e teste, porém nós precisamos criar um terceiro conjunto de validação, para podermos avaliar diversos modelos sem ocorrer overfit nos dados de teste. \n",
    "\n",
    "Assim, separe o conjunto principal em um conjunto de treino (80% dos dados) e um de validação (20% dos dados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE7sNOq-xbxT"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = None, None, None, None\n",
    "\n",
    "######################################################################################\n",
    "# 1. Separe as variáveis X e y em dados de treino e validação, armazenando os resultados nas variáveis acima\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert X_train.shape == (13600, 8) and X_val.shape == (3400, 8) and y_train.shape == (13600,) and y_val.shape == (3400,), 'Erro na separação dos conjuntos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6vzCoj0zH14"
   },
   "source": [
    "# 2. Preprocessamento dos dados \n",
    "\n",
    "Antes de passar os dados para o modelo, é necessário fazer com que eles fiquem aproximadamente na mesma escala. Para isso, vamos considerar duas possibilidades: escalonamento para o intervalo [0,1] e normalização para média 0 e desvio padrão 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTgc5kAlzMI1"
   },
   "outputs": [],
   "source": [
    "def escalonar(data):\n",
    "\n",
    "    ######################################################################################\n",
    "    # 2. Transforme os dados na variável data para que cada coluna tenha um mínimo de 0 e um máximo de 1\n",
    "    # Obs: a variável data pode ser um DataFrame inteiro ou uma coluna\n",
    "    # O objeto MinMaxScaler da sklearn pode ser útil\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert escalonar(X_train).shape == X_train.shape, 'Os dados retornados devem ter o mesmo formato dos originais'\n",
    "assert np.all(np.abs(np.max(escalonar(X_test)) - 1) < 1e-3) and np.all(np.abs(np.min(escalonar(X_test))) < 1e-3), 'Os dados retornados devem ter um mínimo de 0 e um máximo de 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHvDGCx4qZBh"
   },
   "outputs": [],
   "source": [
    "def padronizar(data):\n",
    "\n",
    "    ######################################################################################\n",
    "    # 3. Transforme os dados na variável data para que cada coluna tenha uma média de 0 e um desvio padrão de 1\n",
    "    # Obs: a variável data pode ser um DataFrame inteiro ou uma coluna\n",
    "    # O objeto StandardScaler da sklearn pode ser útil\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert padronizar(X_test).shape == X_test.shape, 'Os dados retornados devem ter o mesmo formato dos originais'\n",
    "assert np.all(np.abs(np.std(padronizar(X_test)) - 1) < 1e-3) and np.all(np.abs(np.mean(padronizar(X_test))) < 1e-3), 'Os dados retornados devem ter uma média de 0 e um desvio padrão de 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cWnEkf22I6W"
   },
   "source": [
    "# 3. Métricas de regressão\n",
    "\n",
    "Uma das principais métricas usadas para regressão é o Erro Quadrático Médio (MSE), que segue a seguinte equação:\n",
    "\n",
    "$\\text{MSE} = \\frac{1}{n}\\sum (Y_{\\text{pred}} - Y_{\\text{true}})^2$\n",
    "\n",
    "\n",
    "Para facilitar a interpretação desse valor, podemos usar a medida R2, que é um valor normalmente entre 0 e 1. Ele é calculado segundo a seguinte equação:\n",
    "\n",
    "$R^2 = 1 - \\frac{\\text{MSE}}{\\text{Var}[Y_{\\text{true}}]}$\n",
    "\n",
    "Assim, implemente as funções para calcular as quantidades acima:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQPzUAgn2k8B"
   },
   "outputs": [],
   "source": [
    "def MSE(y_true, y_pred):\n",
    "\n",
    "    ######################################################################################\n",
    "    # 4. Implemente uma função que retorne o erro quadrádico médio\n",
    "    # y_true: valores verdadeiros da variável\n",
    "    # y_pred: valores preditos pelo modelo\n",
    "    \n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert np.abs(MSE(y_test, np.zeros_like(y_test)) - np.mean(y_test**2)) < 1e-3, 'Erro na função MSE'\n",
    "assert np.abs(MSE(y_test, np.ones_like(y_test)*np.mean(y_test)) - np.var(y_test)) < 1e-3, 'Erro na função MSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uegc9TSs7J2v"
   },
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred):\n",
    "    \n",
    "    ######################################################################################\n",
    "    # 5. Implemente uma função que retorne a medida R2 (pode ser útil reutilizar a função acima)\n",
    "    # y_true: valores verdadeiros da variável\n",
    "    # y_pred: valores preditos pelo modelo\n",
    "    \n",
    "    \n",
    "    ######################################################################################\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert np.abs(R2(y_test, np.zeros_like(y_test)) + np.mean(y_test)**2 / np.var(y_test)) < 1e-3, 'Erro na função R2'\n",
    "assert np.abs(R2(y_test, np.mean(y_test))) < 1e-3, 'Erro na função R2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ur9ZnKPC97y6"
   },
   "source": [
    "# 4. Avaliando o modelo KNN\n",
    "\n",
    "Vamos avaliar a performance do modelo KNN para essa tarefa de regressão, com diferentes tipos de preprocessamento (dados originais, escalonados ou padronizados).\n",
    "\n",
    "Para isso, implemente a função para realizar as predições com um modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWdsXdBq7fXb"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_train, y_train, X_val):\n",
    "    ######################################################################################\n",
    "    # 6. Treine o modelo nos dados de treino e retorne as predições na validação\n",
    "    # A variável model é um modelo da biblioteca sklearn, então a função model.fit pode ser usada\n",
    "    \n",
    "    ######################################################################################\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert np.all(predict(DummyRegressor(), X_train, y_train, X_val) == y_train.mean()), 'Erro na função predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyrMRdJesoLW"
   },
   "outputs": [],
   "source": [
    "def R2_model(model, X_train, y_train, X_val, y_val):\n",
    "\n",
    "    ######################################################################################\n",
    "    # 7. Retorne a medida R2 do modelo treinado (pode ser útil reutilizar a função anterior)\n",
    "    \n",
    "    \n",
    "    ######################################################################################\n",
    "\n",
    "### Verificação de erros ###\n",
    "assert np.abs(R2_model(DummyRegressor(), X_train, y_train, X_val, y_val)) < 1e-3, 'Erro na função R2_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UOJEJAkBwow"
   },
   "source": [
    "Em seguida, vamos avaliar o modelo KNN nos dados de validação com os diferentes tipos de preprocessamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0WxGCWyAfnX",
    "outputId": "1109c56a-b56a-47e4-997e-4379188bee97"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "R2_original = None\n",
    "R2_escalonado = None\n",
    "R2_padronizado = None\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "# 8. Avalie o modelo nos dados de validação em três situações, salvando os resultados nas variáveis acima:\n",
    "# 1. Com os dados originais\n",
    "# 2. Com os dados escalonados\n",
    "# 3. Com os dados padronizados\n",
    "#\n",
    "# OBS: não utilize os dados de teste nesse passo, apenas os de treino e validação!\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print('R2 sem preprocessamento: %.2f' % R2_original)\n",
    "print('R2 com escalonamento entre 0 e 1: %.2f' % R2_escalonado)\n",
    "print('R2 com padronização para média 0 e desvio padrão 1: %.2f' % R2_padronizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZULvBWA7kc1B"
   },
   "source": [
    "Assim, encontre o melhor valor de K para o modelo KNN usando o preprocessamento selecionado no passo anterior, testando todos os valores de K no intervalo de 1 a 30 no conjunto de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bVvBKL3kSEo",
    "outputId": "a85269f6-3954-41b4-881e-aec136469d67"
   },
   "outputs": [],
   "source": [
    "best_k = None\n",
    "best_R2 = None\n",
    "\n",
    "######################################################################################\n",
    "# 9. Encontre o erro do melhor valor de K para o modelo KNN usando o preprocessamento encontrado no passo anterior\n",
    "# OBS: não utilize os dados de teste nesse passo, apenas os de treino e validação!\n",
    "#\n",
    "# Dica: Para criar um modelo KNN com um valor específico de K, use KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print('Melhor valor de k encontrado: %d' % best_k)\n",
    "print('Melhor erro R2 na validação encontrado: %.2f' % best_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_Jokhfcl0TM"
   },
   "source": [
    "Finalmente, podemos usar o valor ótimo encontrado para avaliar o modelo nos dados de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inPGFfaul5Wg",
    "outputId": "46c7c9b2-2763-4594-94ee-1aabe4a52088"
   },
   "outputs": [],
   "source": [
    "test_R2 = None\n",
    "\n",
    "######################################################################################\n",
    "# 10. Encontre o erro do modelo encontrado nos dados de teste\n",
    "# Para isso, use o valor de k e o preprocessamento ótimos encontrados\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print('Erro final encontrado no teste: %.2f' % test_R2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula05",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
