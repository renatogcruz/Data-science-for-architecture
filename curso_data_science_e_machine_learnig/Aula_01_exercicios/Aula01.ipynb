{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução à Data Science e Machine Learning - Data ICMC-USP\n",
    "\n",
    "## Prática Aula 01 - k-Nearest Neighbors\n",
    "\n",
    "Esse material foi desenvolvido pelo **Data**, grupo de extensão de aprendizado e ciência de dados compostos por alunos do Instituto de Ciências Matemáticas e de Computação da USP\n",
    "\n",
    "Para saber mais sobre as atividades do Data entre no nosso site e nos siga e nossas redes sociais:\n",
    "- [Site](http://data.icmc.usp.br/)\n",
    "- [Twitter](https://twitter.com/data_icmc)\n",
    "- [LinkedIn](https://www.linkedin.com/school/data-icmc/)\n",
    "- [Facebook](https://www.facebook.com/dataICMC/)\n",
    "\n",
    "Aproveite o material!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar carregando os dados que iremos usar no nossa tarefa. Esses dados fornecem várias informações a respeito de diferentes vinhos e o objetivo é classificar se o vinho é bom (target é a coluna *is_good*).\n",
    "\n",
    "Esse conjunto de dados é uma modificação do conjunto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "\n",
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "#  - Leia os dados de data.csv com pd.read_csv e guarde      #\n",
    "# na variável df                                             #\n",
    "##############################################################\n",
    "\n",
    "df = None\n",
    "\n",
    "##############################################################\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "#  - Guarde o shape do DataFrame na viarável  shape          #\n",
    "##############################################################\n",
    "\n",
    "shape = None\n",
    "\n",
    "##############################################################\n",
    "\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deixando os dados na mesma escala\n",
    "Para vários algoritmos é importante deixarmos os dados em uma mesma escala, e o kNN um desses casos. Para entender melhor vamos olhar o exemplo a seguir:\n",
    "\n",
    "<img src=\"imgs/grafico_escala.png\" style=\"width: 400px\"/>\n",
    "\n",
    "Nesse caso a distância entre os dois pontos é dada por\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{dist}(x^{(1)}, x^{(2)}) &= \\sqrt{(x^{(1)}_1 - x^{(2)}_1)^2 + (x^{(1)}_2 - x^{(2)}_2)^2} \\\\\n",
    "  &= \\sqrt{(3 - 2)^2 + (10000 - 9000)^2} \\\\\n",
    "  &= \\sqrt{1 + 1000000} \\\\\n",
    "  &= \\sqrt{1000001} \\\\\n",
    "  &= 1000.0005\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "Como as escalas são muito diferentes o primeiro atributo acaba não interferindo em praticamente nada no resultado da distância. E é importante perceber que esse tipo de situação ocorre com frequência em conjuntos de dados reais.\n",
    "\n",
    "Existem diversas formas de tratar essa situação, aqui usaremos uma técnica chamada **Min-Max Scaling**, que transforma os dados deixando-os no intervalo $[0, 1]$. A formula é da transformação é a seguinte:\n",
    "\n",
    "$$x^{(i)}_j \\leftarrow \\frac{x^{(i)}_j - min(x_j)}{max(x_j) - min(x_j)}$$\n",
    "\n",
    "Em palavras significa que vamos subtrair o menor valor da atributo e dividir pela amplitude (diferença entre o máximo e o mínimo).\n",
    "\n",
    "\n",
    "Pronto, agora que entendemos podemos fazer fazer isso para todas as nossas colunas utilizando a função interna do scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "df = pd.DataFrame(scaler.transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos dados em treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'is good'\n",
    "features = df.columns.to_list()\n",
    "features.remove(target)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[features], df[target], test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = None\n",
    "y_pred = None\n",
    "\n",
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "#  - Instancie um KNeighborsClassifier na variável clf       #\n",
    "#  - Treine o classificador com X_train e y_train            #\n",
    "#  - Faça a predições para os dados de validade e salve      #\n",
    "# em y_pred                                                  #\n",
    "##############################################################\n",
    "\n",
    "clf = None\n",
    "y_pred = None\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = None\n",
    "\n",
    "##############################################################\n",
    "#                       PREENCHA AQUI:                       #\n",
    "#  - Calcule a acurácia do modelo que você treinou usando a  #\n",
    "# função accuracy_score, salve o resultado e o imprima       #\n",
    "##############################################################\n",
    "\n",
    "acc = None\n",
    "\n",
    "##############################################################\n",
    "\n",
    "print(f'A acurácia foi de {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorando variações no modelo\n",
    "\n",
    "#### Número de vizinhos\n",
    "\n",
    "O principal hiperparâmetro do kNN é justamente o número de vizinhos, representado pelo k. Por padrão o `KNeighborsClassifier()` usa cinco vizinhos, através de seu parâmetro `n_neighbors` é possível alterar este valor.\n",
    "\n",
    "#### Métrica de distância\n",
    "\n",
    "Como vimos na aula, é possível utilizar diferentes metricas de distancia entre pontos, e vimos as duas seguintes:\n",
    "\n",
    "- Distância Euclidiana => $dist(a, b) = \\sqrt{\\sum_i (a_i - b_i)^2}$\n",
    "- Distância Manhattan => $dist(a, b) = \\sum_i |a_i - b_i|$\n",
    "\n",
    "O sklearn, por outro lado, faz uso de uma generalização destas duas distâncias, chamada distância **Minkowski** =>\n",
    "$dist(a, b) = (\\sum_i |a_i - b_i|^p)^\\frac{1}{p}$. Perceba que com $p=2$ temos a distância Euclidiano e com $p=1$ temos a distância Manhattan. \n",
    "\n",
    "Por padrão a classe `KNeighborsClassifier()` usa `p=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vizinhos = [3, 5, 7, 9, 11, 13]\n",
    "resultados = []\n",
    "\n",
    "for k in n_vizinhos:\n",
    "    ##############################################################\n",
    "    #                       PREENCHA AQUI:                       #\n",
    "    #  - Crie um kNN com k vizinhos e utilizando distância       #\n",
    "    # Manhattan                                                  #\n",
    "    # - Treine esse modelo com X_train e y_train                 #\n",
    "    # - Calcule a acurácia do modelo que você treinou e salve    #\n",
    "    # o resultado na lista resultados                            #\n",
    "    ##############################################################\n",
    "    \n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "for k, acc in zip(n_vizinhos, resultados):\n",
    "    print(f'{k:02d} vizinhos => Acurácia {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
